{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-10-13T15:46:03.164647Z","iopub.execute_input":"2021-10-13T15:46:03.165119Z","iopub.status.idle":"2021-10-13T15:46:03.179184Z","shell.execute_reply.started":"2021-10-13T15:46:03.165058Z","shell.execute_reply":"2021-10-13T15:46:03.178081Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"filenames=os.listdir('../input/agriculture-crop-images/crop_images')\n","metadata":{"execution":{"iopub.status.busy":"2021-10-13T15:46:03.187701Z","iopub.execute_input":"2021-10-13T15:46:03.188149Z","iopub.status.idle":"2021-10-13T15:46:03.202353Z","shell.execute_reply.started":"2021-10-13T15:46:03.188102Z","shell.execute_reply":"2021-10-13T15:46:03.201172Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df=pd.DataFrame({'filename':filenames})","metadata":{"execution":{"iopub.status.busy":"2021-10-13T15:46:03.204617Z","iopub.execute_input":"2021-10-13T15:46:03.205172Z","iopub.status.idle":"2021-10-13T15:46:03.215323Z","shell.execute_reply.started":"2021-10-13T15:46:03.205115Z","shell.execute_reply":"2021-10-13T15:46:03.213665Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2021-10-13T15:46:03.217364Z","iopub.execute_input":"2021-10-13T15:46:03.218176Z","iopub.status.idle":"2021-10-13T15:46:03.31247Z","shell.execute_reply.started":"2021-10-13T15:46:03.218131Z","shell.execute_reply":"2021-10-13T15:46:03.311356Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.preprocessing.image import ImageDataGenerator","metadata":{"execution":{"iopub.status.busy":"2021-10-13T15:46:03.315632Z","iopub.execute_input":"2021-10-13T15:46:03.3163Z","iopub.status.idle":"2021-10-13T15:46:08.880988Z","shell.execute_reply.started":"2021-10-13T15:46:03.31625Z","shell.execute_reply":"2021-10-13T15:46:08.879918Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_gen=ImageDataGenerator(shear_range=0.2, zoom_range=0.2, horizontal_flip=True,rotation_range=0.2,width_shift_range=0.2,height_shift_range=0.2)","metadata":{"execution":{"iopub.status.busy":"2021-10-13T15:46:08.8838Z","iopub.execute_input":"2021-10-13T15:46:08.884421Z","iopub.status.idle":"2021-10-13T15:46:08.89069Z","shell.execute_reply.started":"2021-10-13T15:46:08.884378Z","shell.execute_reply":"2021-10-13T15:46:08.889265Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data1=data_gen.flow_from_directory('../input/agriculture-crop-images/kag2',target_size=(224,224))\ntrain_data2=data_gen.flow_from_directory('../input/agriculture-crop-images/crop_images',target_size=(224,224))\ntrain_data3=data_gen.flow_from_directory('../input/agriculture-crop-images/some_more_images/some_more_images',target_size=(224,224))","metadata":{"execution":{"iopub.status.busy":"2021-10-13T15:46:08.894814Z","iopub.execute_input":"2021-10-13T15:46:08.895266Z","iopub.status.idle":"2021-10-13T15:46:09.232266Z","shell.execute_reply.started":"2021-10-13T15:46:08.89523Z","shell.execute_reply":"2021-10-13T15:46:09.231191Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.applications import ResNet50","metadata":{"execution":{"iopub.status.busy":"2021-10-13T15:46:09.237578Z","iopub.execute_input":"2021-10-13T15:46:09.237979Z","iopub.status.idle":"2021-10-13T15:46:09.245548Z","shell.execute_reply.started":"2021-10-13T15:46:09.237946Z","shell.execute_reply":"2021-10-13T15:46:09.244331Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"resnet=ResNet50(include_top=False,input_shape=(224,224,3))","metadata":{"execution":{"iopub.status.busy":"2021-10-13T15:46:09.250409Z","iopub.execute_input":"2021-10-13T15:46:09.250762Z","iopub.status.idle":"2021-10-13T15:46:16.311603Z","shell.execute_reply.started":"2021-10-13T15:46:09.250732Z","shell.execute_reply":"2021-10-13T15:46:16.310337Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"resnet.summary()","metadata":{"execution":{"iopub.status.busy":"2021-10-13T15:46:16.313506Z","iopub.execute_input":"2021-10-13T15:46:16.313991Z","iopub.status.idle":"2021-10-13T15:46:16.441143Z","shell.execute_reply.started":"2021-10-13T15:46:16.313935Z","shell.execute_reply":"2021-10-13T15:46:16.440019Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for layer in resnet.layers:\n    layer.trainable= False\nresnet.summary()","metadata":{"execution":{"iopub.status.busy":"2021-10-13T15:46:16.442859Z","iopub.execute_input":"2021-10-13T15:46:16.443332Z","iopub.status.idle":"2021-10-13T15:46:16.707843Z","shell.execute_reply.started":"2021-10-13T15:46:16.443272Z","shell.execute_reply":"2021-10-13T15:46:16.70672Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.layers import Flatten, Dense\nfrom tensorflow.keras.models import Model","metadata":{"execution":{"iopub.status.busy":"2021-10-13T15:46:16.709655Z","iopub.execute_input":"2021-10-13T15:46:16.710147Z","iopub.status.idle":"2021-10-13T15:46:16.718048Z","shell.execute_reply.started":"2021-10-13T15:46:16.710101Z","shell.execute_reply":"2021-10-13T15:46:16.716695Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"resnet_Flatten=Flatten()(resnet.output)\ntop_layer=Dense(5,activation='softmax')(resnet_Flatten)\ntop_layer","metadata":{"execution":{"iopub.status.busy":"2021-10-13T15:46:16.721876Z","iopub.execute_input":"2021-10-13T15:46:16.722205Z","iopub.status.idle":"2021-10-13T15:46:16.748819Z","shell.execute_reply.started":"2021-10-13T15:46:16.722175Z","shell.execute_reply":"2021-10-13T15:46:16.747391Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"my_resnet_model=Model(inputs=resnet.input, outputs=top_layer)\nmy_resnet_model.summary()","metadata":{"execution":{"iopub.status.busy":"2021-10-13T15:46:16.75062Z","iopub.execute_input":"2021-10-13T15:46:16.751242Z","iopub.status.idle":"2021-10-13T15:46:16.895142Z","shell.execute_reply.started":"2021-10-13T15:46:16.751184Z","shell.execute_reply":"2021-10-13T15:46:16.893987Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"my_resnet_model.compile(loss='categorical_crossentropy', metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2021-10-13T15:46:16.896895Z","iopub.execute_input":"2021-10-13T15:46:16.897305Z","iopub.status.idle":"2021-10-13T15:46:16.919436Z","shell.execute_reply.started":"2021-10-13T15:46:16.897261Z","shell.execute_reply":"2021-10-13T15:46:16.918199Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf","metadata":{"execution":{"iopub.status.busy":"2021-10-13T15:48:03.079637Z","iopub.execute_input":"2021-10-13T15:48:03.080179Z","iopub.status.idle":"2021-10-13T15:48:03.085603Z","shell.execute_reply.started":"2021-10-13T15:48:03.080146Z","shell.execute_reply":"2021-10-13T15:48:03.084233Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ACCURACY_THRESHOLD = 0.95","metadata":{"execution":{"iopub.status.busy":"2021-10-13T15:48:07.511531Z","iopub.execute_input":"2021-10-13T15:48:07.511948Z","iopub.status.idle":"2021-10-13T15:48:07.517153Z","shell.execute_reply.started":"2021-10-13T15:48:07.511903Z","shell.execute_reply":"2021-10-13T15:48:07.515777Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# class myCallback(tf.keras.callbacks.Callback): \n#     def on_epoch_end(self, epoch, logs={}): \n#         if(logs.get('acc') > ACCURACY_THRESHOLD):   \n#             print(\"\\nReached %2.2f%% accuracy, so stopping training!!\" %(ACCURACY_THRESHOLD*100))   \n#             self.model.stop_training = True","metadata":{"execution":{"iopub.status.busy":"2021-10-13T15:48:27.447068Z","iopub.execute_input":"2021-10-13T15:48:27.447422Z","iopub.status.idle":"2021-10-13T15:48:27.454603Z","shell.execute_reply.started":"2021-10-13T15:48:27.447388Z","shell.execute_reply":"2021-10-13T15:48:27.452541Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# callbacks = myCallback()","metadata":{"execution":{"iopub.status.busy":"2021-10-13T15:48:30.798847Z","iopub.execute_input":"2021-10-13T15:48:30.79923Z","iopub.status.idle":"2021-10-13T15:48:30.804877Z","shell.execute_reply.started":"2021-10-13T15:48:30.799199Z","shell.execute_reply":"2021-10-13T15:48:30.803152Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"my_callbacks = [\n    tf.keras.callbacks.EarlyStopping(patience=2),\n    tf.keras.callbacks.ModelCheckpoint(filepath='model.{epoch:02d}-{val_loss:.2f}.h5'),\n    tf.keras.callbacks.TensorBoard(log_dir='./logs'),\n]","metadata":{"execution":{"iopub.status.busy":"2021-10-13T15:57:26.511257Z","iopub.execute_input":"2021-10-13T15:57:26.511735Z","iopub.status.idle":"2021-10-13T15:57:26.839808Z","shell.execute_reply.started":"2021-10-13T15:57:26.511697Z","shell.execute_reply":"2021-10-13T15:57:26.838597Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"my_resnet_model.fit(train_data1, epochs=50, callbacks=my_callbacks)","metadata":{"execution":{"iopub.status.busy":"2021-10-13T15:57:30.123564Z","iopub.execute_input":"2021-10-13T15:57:30.124024Z","iopub.status.idle":"2021-10-13T15:57:42.286582Z","shell.execute_reply.started":"2021-10-13T15:57:30.123986Z","shell.execute_reply":"2021-10-13T15:57:42.283999Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import cv2","metadata":{"execution":{"iopub.status.busy":"2021-10-13T15:46:16.951967Z","iopub.status.idle":"2021-10-13T15:46:16.952892Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_class(img_path):\n    img=cv2.imread(img_path)\n    img=cv2.resize(img,(224,224))/255\n    img=img.reshape(1,224,224,3)\n    index=my_resnet_model.predict(img).argmax()\n    return 'jute' if index==0 else 'maize' if index == 1 else 'rice' if index == 2 else 'sugarcane' if index==3 else 'wheat'","metadata":{"execution":{"iopub.status.busy":"2021-10-13T15:46:16.954713Z","iopub.status.idle":"2021-10-13T15:46:16.955533Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"get_class('../input/agriculture-crop-images/test_crop_image/wheatcropfield04.jpg')","metadata":{"execution":{"iopub.status.busy":"2021-10-13T15:46:16.957611Z","iopub.status.idle":"2021-10-13T15:46:16.958657Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"get_class('../input/agriculture-crop-images/test_crop_image/maize-Field-Corn.jpg')","metadata":{"execution":{"iopub.status.busy":"2021-10-13T15:46:16.960897Z","iopub.status.idle":"2021-10-13T15:46:16.961726Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"get_class('../input/agriculture-crop-images/test_crop_image/wheat-field-395545_960_720.jpg')","metadata":{"execution":{"iopub.status.busy":"2021-10-13T15:46:16.963956Z","iopub.status.idle":"2021-10-13T15:46:16.965032Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"get_class('../input/agriculture-crop-images/test_crop_image/rice-828540_1280.jpg')","metadata":{"execution":{"iopub.status.busy":"2021-10-13T15:46:16.967098Z","iopub.status.idle":"2021-10-13T15:46:16.968143Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"get_class('../input/agriculture-crop-images/test_crop_image/maizecornleaves.jfif')","metadata":{"execution":{"iopub.status.busy":"2021-10-13T15:46:16.970732Z","iopub.status.idle":"2021-10-13T15:46:16.971626Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}